# Code Review Guide

**Purpose:** Guide for reviewers to assess analysis code quality and reproducibility

**Status:** Ready for peer review

---

## Quick Start for Reviewers

### 1. Repository Overview (5 minutes)

Read these files in order:
1. `README.md` - Project overview and key findings
2. `SCRIPT_MANIFEST.md` - What each script does
3. `REPRODUCIBILITY_GUIDE.md` - How to reproduce analyses

### 2. Key Files to Review (30 minutes)

**Primary analysis scripts:**
1. `scripts/MRB/6.coral-growth.R` - **Most important** (allometric growth analysis)
2. `scripts/MRB/7.coral-physiology.R` - Physiology + integrated performance
3. `scripts/MRB/8.cafi-coral-community.R` - CAFI-coral relationships

**Statistical outputs:**
1. `output/MRB/MANUSCRIPT_STATS_TABLE.csv` - All statistical test results
2. `output/MRB/KEY_STATISTICS_FOR_MANUSCRIPT.md` - Key results summary

### 3. Run Analysis (10 minutes)

```bash
# Test Scripts 6, 7, 8, and 14
Rscript scripts/MRB/6.coral-growth.R
Rscript scripts/MRB/7.coral-physiology.R
Rscript scripts/MRB/8.cafi-coral-community.R
Rscript scripts/MRB/14.compile-manuscript-statistics.R
```

Verify outputs match expected results (see REPRODUCIBILITY_GUIDE.md).

---

## Code Review Checklist

### General Code Quality

- [ ] **Code organization:** Scripts are well-organized and numbered
- [ ] **Comments:** All scripts have clear headers and inline comments
- [ ] **Functions:** Complex operations broken into clear steps
- [ ] **Variable names:** Descriptive and consistent
- [ ] **Dependencies:** All required packages listed
- [ ] **File paths:** Use `here()` package for portability

### Statistical Rigor

- [ ] **Model specification:** Models are correctly specified
- [ ] **Assumptions:** Model assumptions checked (documented in scripts)
- [ ] **Random effects:** Appropriate random effects structure (reef as random intercept)
- [ ] **Multiple testing:** Corrections applied where needed (Benjamini-Hochberg, Tukey)
- [ ] **Post-hoc tests:** Appropriate corrections for pairwise comparisons
- [ ] **Model comparison:** LRT used correctly for nested models

### Reproducibility

- [ ] **Data availability:** All required data files present
- [ ] **Code runs:** Scripts execute without errors
- [ ] **Results match:** Outputs match reported statistics
- [ ] **Documentation:** Clear instructions for reproduction
- [ ] **Dependencies:** Package versions documented
- [ ] **Seed setting:** Random processes reproducible

### Manuscript Alignment

- [ ] **Statistics match:** All manuscript statistics match code outputs
- [ ] **Figures match:** All manuscript figures generated by code
- [ ] **Methods match:** Statistical methods accurately described
- [ ] **Sample sizes:** Reported sample sizes correct (*n* = 44)

---

## Key Statistical Decisions to Review

### 1. Unified Allometric Model (Script 6)

**Decision:** Use unified *b* = 0.6986 for all size-corrections

**Justification:**
- Interaction was significant (*p* = 0.039)
- BUT no pairwise differences after Tukey adjustment (all *p* > 0.07)
- AND model comparison marginal (*p* = 0.073)
- AND high uncertainty in some treatment-specific slopes (SE = 0.38 for 3-colony)

**Review Question:** Is this justified given the significant interaction?

**Supporting Evidence:**
- Osenberg (pers. comm.) recommendation
- More precise estimate using full dataset (*n* = 44 vs. ~15 per treatment)
- Conservative approach (unified correction)
- Robustness checks with alternative metrics all concordant

**Alternative Considered:** Use treatment-specific corrections
- Problem: High uncertainty, no significant pairwise differences

**Code Location:** Lines 200-350 in `scripts/MRB/6.coral-growth.R`

### 2. Multiple Testing Correction (Script 7)

**Decision:** Apply Benjamini-Hochberg correction to physiology metrics

**Justification:**
- Testing 5 metrics (carbohydrate, protein, zooxanthellae, AFDW, PC1)
- Family-wise error rate would be inflated

**Result:** Only carbohydrate remains significant after correction

**Code Location:** Lines 150-180 in `scripts/MRB/7.coral-physiology.R`

### 3. Random Effects Structure

**Decision:** Use `(1|reef)` in all models

**Justification:**
- Experimental design: corals nested within reefs
- Reefs arranged in spatial grid (shared environment)
- Colonies on same reef not independent

**Review Question:** Is this the correct random effects structure?

**Alternative Considered:** `(1 + treatment|reef)`
- Problem: Only 3-8 reefs per treatment, insufficient for random slopes

**Code Location:** All `lmer()` calls in Scripts 6, 7, 8

### 4. Data Filtering (Script 1)

**Decision:** Exclude colonies with <80% tissue alive

**Sample size impact:** 54 → 44 colonies

**Justification:**
- Partially dead colonies may exhibit altered growth
- Tissue loss affects physiological measurements
- Conservative threshold

**Review Question:** Is 80% the appropriate threshold?

**Code Location:** Lines 50-70 in `scripts/MRB/1.data-organization.R`

---

## Common Review Questions

### Q1: Why is the interaction (*p* = 0.039) not emphasized more?

**Answer:**
- Post-hoc tests show no significant pairwise differences
- Model comparison is marginal (*p* = 0.073)
- High uncertainty in 3-colony slope estimate
- Unified *b* provides more robust, comparable metric
- Main biological finding is NO treatment effect on size-corrected growth

**Manuscript approach:**
- Report interaction in Methods (Analytic approach) as part of model selection
- Report lack of treatment effect in Results as main finding
- Discuss in Discussion if desired

### Q2: Why use Type III Wald χ² instead of likelihood ratio tests?

**Answer:**
- Type III appropriate for balanced designs
- lmerTest provides Type III by default for fixed effects
- LRT used for model comparison (interaction vs parallel slopes)
- Both approaches give same qualitative conclusions

**Code:** `anova()` calls use Type III Wald χ² from lmerTest

### Q3: Are the transformation choices for CAFI-coral analysis justified?

**Answer:**
- Multiple transformations tested for robustness
- All three transformations (SQRT_CS, HELLINGER, SQRT) show significant relationship
- This demonstrates finding is not transformation-dependent
- Conservative approach (report all three)

**Code Location:** Lines 100-200 in `scripts/MRB/8.cafi-coral-community.R`

### Q4: Why Principal Components Analysis instead of individual metrics?

**Answer:**
- PC1 creates integrated measure of coral performance
- Reduces dimensionality (5 metrics → 1 axis)
- Captures coordinated variation
- Still report individual metrics separately

**Interpretation:**
- PC1 explains 52.5% of total variance
- All metrics load positively
- Higher PC1 = better overall condition

**Code Location:** Lines 120-160 in `scripts/MRB/7.coral-physiology.R`

---

## Specific Code Review Focus Areas

### Script 6: Coral Growth (PRIMARY FOCUS)

**Lines to review carefully:**

1. **Lines 50-100:** Data filtering and quality checks
   - Verify 80% tissue threshold applied correctly
   - Check initial vs final volume matching

2. **Lines 200-250:** Interaction model
   - Model specification correct?
   - Interaction test appropriate?

3. **Lines 260-310:** Post-hoc comparisons
   - emtrends() used correctly?
   - Tukey adjustment applied?

4. **Lines 320-370:** Unified model
   - Parallel slopes model specified correctly?
   - Unified *b* extracted correctly?

5. **Lines 380-420:** Size-corrected growth calculation
   - Metric calculated correctly?
   - Treatment effect test appropriate?

6. **Lines 430-480:** Alternative metrics
   - SA-scaled growth calculated correctly?
   - ΔV ~ SA models specified correctly?

### Script 7: Coral Physiology

**Lines to review:**

1. **Lines 80-120:** Individual metric models
   - All metrics modeled correctly?
   - Random effects appropriate?

2. **Lines 150-180:** Multiple testing correction
   - BH correction applied correctly?
   - Interpretation correct?

3. **Lines 200-250:** PC analysis
   - PCA on correct variables?
   - Scaling applied?

### Script 8: CAFI-Coral Relationships

**Lines to review:**

1. **Lines 100-150:** CAFI community PCA
   - Transformations applied correctly?
   - PCA on appropriate matrix?

2. **Lines 200-250:** CAFI → Coral models
   - Model specification correct?
   - Multiple transformations justified?

---

## Expected Outputs

### Console Output from Script 6

```
══ Coral Growth Analysis ══

Testing interaction model...
Interaction: χ² = 6.48, p = 0.039 *

Treatment-specific slopes:
  1 colony: b = 0.781 (SE = 0.161)
  3 colonies: b = -0.099 (SE = 0.377)
  6 colonies: b = 1.004 (SE = 0.304)

Post-hoc comparisons (Tukey):
  1 vs 3: p = 0.094
  1 vs 6: p = 0.795
  3 vs 6: p = 0.072

Model comparison (LRT): χ² = 5.231, p = 0.073

Unified model:
  b = 0.6986

Size-corrected growth by treatment:
  χ² = 2.64, p = 0.267 (NS)

Alternative metrics:
  SA-scaled: χ² = 3.24, p = 0.198 (NS)
  ΔV ~ SA (treatment): χ² = 2.46, p = 0.292 (NS)
  ΔV ~ SA (interaction): χ² = 1.92, p = 0.383 (NS)

✓ All analyses complete
```

### Generated Files

**Verify these files exist:**
- `output/MRB/figures/coral/*.png` (3 growth figures)
- `output/MRB/figures/physiology/*.png` (physiology figures)
- `output/MRB/figures/cafi-coral/*.png` (relationship figures)
- `output/MRB/tables/MANUSCRIPT_STATISTICAL_TESTS.csv`
- `output/MRB/MANUSCRIPT_STATS_TABLE.csv`

---

## Red Flags to Watch For

### Statistical Red Flags

- [ ] **p-hacking:** Multiple testing without correction
- [ ] **HARKing:** Results presented as a priori hypotheses
- [ ] **Model overfitting:** Random effects structure too complex
- [ ] **Assumption violations:** Models used inappropriately
- [ ] **Selective reporting:** Some tests not reported

**Status:** None detected in this analysis

### Code Quality Red Flags

- [ ] **Hardcoded values:** Magic numbers without explanation
- [ ] **Copy-paste errors:** Duplicated code with inconsistencies
- [ ] **Missing checks:** No verification of assumptions
- [ ] **Poor documentation:** Unclear what code does
- [ ] **Non-reproducible:** Results vary between runs

**Status:** None detected in this code

---

## Reviewer Recommendations

### Approve if:
- Code runs successfully
- Results match manuscript
- Statistical approaches justified
- Documentation clear
- No major red flags

### Request revisions if:
- Code doesn't run
- Results don't match manuscript
- Statistical decisions unjustified
- Documentation insufficient
- Major methodological concerns

### Specific things to verify:
1. Unified *b* approach justified given significant interaction
2. Random effects structure appropriate
3. Multiple testing correction applied correctly
4. Data filtering threshold appropriate
5. All manuscript statistics traceable to code

---

## Additional Resources

**For reviewers new to R:**
- Scripts are heavily commented
- Each major step explained
- Statistical output clearly labeled

**For statistical review:**
- All model formulas explicitly written
- Assumptions checked (see inline comments)
- Alternative approaches considered and documented

**For reproducibility review:**
- REPRODUCIBILITY_GUIDE.md has step-by-step instructions
- Expected outputs documented
- Package versions recorded with sessionInfo()

---

## Contact

**Questions about code:** adrian.stier@ucsb.edu

**Statistical consultation:** Craig Osenberg (osenberg@uga.edu)

---

**Last Updated:** November 15, 2025
**Status:** Ready for code review
